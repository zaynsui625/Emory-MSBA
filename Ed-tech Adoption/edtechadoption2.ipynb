{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\" face=\"Times\">Education Technology Adoption</font>\n",
    "\n",
    "<font size=\"2\" face=\"Times\">Richard, Zayn, and Stanson</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_name in list(globals().keys()):\n",
    "    if not var_name.startswith(\"__\"):  # Exclude built-in variables\n",
    "        del globals()[var_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "# import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'_oh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ziyuan Sui\\MSBA\\RA\\GARG\\edtechadoption2.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ziyuan%20Sui/MSBA/RA/GARG/edtechadoption2.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39mgetcwd()\n",
      "File \u001b[1;32mc:\\Users\\jacks\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\displayhook.py:263\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_output_prompt()\n\u001b[0;32m    262\u001b[0m format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_format_data(result)\n\u001b[1;32m--> 263\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_user_ns(result)\n\u001b[0;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_exec_result(result)\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m format_dict:\n",
      "File \u001b[1;32mc:\\Users\\jacks\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\displayhook.py:201\u001b[0m, in \u001b[0;36mDisplayHook.update_user_ns\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m\"\"\"Update user_ns with various things like _, __, _1, etc.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39m# Avoid recursive reference when displaying _oh/Out\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_size \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49muser_ns[\u001b[39m'\u001b[39;49m\u001b[39m_oh\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[0;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns[\u001b[39m'\u001b[39m\u001b[39m_oh\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_size \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_full_cache:\n\u001b[0;32m    203\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcull_cache()\n",
      "\u001b[1;31mKeyError\u001b[0m: '_oh'"
     ]
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will set max rows to None, which means it will display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "platforms = pd.read_csv(r\"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\data\\EducationTechPlatforms.csv\")\n",
    "lst = platforms.iloc[:,0].str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 952: expected 119 fields, saw 188\\nSkipping line 953: expected 119 fields, saw 199\\nSkipping line 1091: expected 119 fields, saw 366\\nSkipping line 1166: expected 119 fields, saw 155\\nSkipping line 1262: expected 119 fields, saw 313\\nSkipping line 1561: expected 119 fields, saw 163\\nSkipping line 1563: expected 119 fields, saw 241\\nSkipping line 1694: expected 119 fields, saw 235\\nSkipping line 1751: expected 119 fields, saw 145\\nSkipping line 1752: expected 119 fields, saw 125\\nSkipping line 1774: expected 119 fields, saw 261\\nSkipping line 1925: expected 119 fields, saw 498\\nSkipping line 1926: expected 119 fields, saw 120\\nSkipping line 1954: expected 119 fields, saw 176\\nSkipping line 1983: expected 119 fields, saw 185\\nSkipping line 1985: expected 119 fields, saw 185\\nSkipping line 2053: expected 119 fields, saw 272\\nSkipping line 2054: expected 119 fields, saw 277\\nSkipping line 2055: expected 119 fields, saw 274\\nSkipping line 2056: expected 119 fields, saw 278\\nSkipping line 2074: expected 119 fields, saw 469\\nSkipping line 2263: expected 119 fields, saw 240\\nSkipping line 2318: expected 119 fields, saw 128\\nSkipping line 2755: expected 119 fields, saw 168\\nSkipping line 2873: expected 119 fields, saw 146\\nSkipping line 3626: expected 119 fields, saw 153\\nSkipping line 3697: expected 119 fields, saw 152\\nSkipping line 3890: expected 119 fields, saw 133\\nSkipping line 4101: expected 119 fields, saw 219\\nSkipping line 4265: expected 119 fields, saw 155\\nSkipping line 4268: expected 119 fields, saw 214\\nSkipping line 4278: expected 119 fields, saw 161\\nSkipping line 4576: expected 119 fields, saw 234\\nSkipping line 4613: expected 119 fields, saw 121\\nSkipping line 4629: expected 119 fields, saw 140\\nSkipping line 4734: expected 119 fields, saw 125\\nSkipping line 4944: expected 119 fields, saw 213\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\data\\text_noToken2.csv\", encoding='latin-1', on_bad_lines='warn', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the text data\n",
    "df['text'] = df.iloc[:, 1:].apply(lambda row: ' '.join(row.dropna()), axis=1)\n",
    "# Initialize a CountVectorizer\n",
    "vectorizer = CountVectorizer(vocabulary=lst)\n",
    "# Fit the vectorizer and transform the text data into a document-term matrix\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "# Create a DataFrame from the document-term matrix\n",
    "counts_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# Add the school names to the counts_df\n",
    "counts_df['school'] = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'_oh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ziyuan Sui\\MSBA\\RA\\GARG\\edtechadoption2.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ziyuan%20Sui/MSBA/RA/GARG/edtechadoption2.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m counts_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\jacks\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\displayhook.py:263\u001b[0m, in \u001b[0;36mDisplayHook.__call__\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_output_prompt()\n\u001b[0;32m    262\u001b[0m format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_format_data(result)\n\u001b[1;32m--> 263\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_user_ns(result)\n\u001b[0;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_exec_result(result)\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m format_dict:\n",
      "File \u001b[1;32mc:\\Users\\jacks\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\displayhook.py:201\u001b[0m, in \u001b[0;36mDisplayHook.update_user_ns\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m\"\"\"Update user_ns with various things like _, __, _1, etc.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39m# Avoid recursive reference when displaying _oh/Out\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_size \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49muser_ns[\u001b[39m'\u001b[39;49m\u001b[39m_oh\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[0;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns[\u001b[39m'\u001b[39m\u001b[39m_oh\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_size \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_full_cache:\n\u001b[0;32m    203\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcull_cache()\n",
      "\u001b[1;31mKeyError\u001b[0m: '_oh'"
     ]
    }
   ],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df['total'] = counts_df.drop('school', axis=1).sum(axis=1)\n",
    "filtered_df = counts_df[counts_df['total'] > 0]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\data\"\n",
    "# Get all the file names in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter the file names to include only CSV files\n",
    "csv_files = [file for file in files if file.startswith(\"text_\")]\n",
    "\n",
    "# Print the list of CSV file names\n",
    "for file_name in csv_files:\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the final results\n",
    "final_df = pd.DataFrame()\n",
    "#Loop through each CSV file\n",
    "for file_name in csv_files:\n",
    "    df = pd.read_csv(directory + \"\\\\\" + file_name, encoding='latin-1', on_bad_lines='warn', header=None)\n",
    "    # Flatten the text data\n",
    "    df['text'] = df.iloc[:, 1:].apply(lambda row: ' '.join(row.dropna()), axis=1)\n",
    "    # Initialize a CountVectorizer\n",
    "    vectorizer = CountVectorizer(vocabulary=lst)\n",
    "    # Fit the vectorizer and transform the text data into a document-term matrix\n",
    "    X = vectorizer.fit_transform(df['text'])\n",
    "    # Create a DataFrame from the document-term matrix\n",
    "    counts_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    # Add the school names to the counts_df\n",
    "    counts_df['school'] = df[0]\n",
    "    counts_df['total'] = counts_df.drop('school', axis=1).sum(axis=1)\n",
    "    filtered_df = counts_df[counts_df['total'] > 0]\n",
    "    final_df = final_df.append(filtered_df, ignore_index=True)\n",
    "# Display the final DataFrame\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.school.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df.school == 'sites.google.com63048.html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(r\"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\data\\final_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_counts = final_df.school.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_schools = school_counts[school_counts == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique=final_df[final_df['school'].isin(unique_schools)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_schools = school_counts[school_counts == 2].index\n",
    "df_duplicates = final_df[final_df['school'].isin(duplicate_schools)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = final_df.columns.drop('school')\n",
    "df_duplicates_mean = df_duplicates.groupby('school')[numeric_columns].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = pd.concat([df_unique, df_duplicates_mean], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2.to_csv(r\"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\data\\final_df2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dct = {}\n",
    "# with open(\"/Users/richardhuang/Documents/Garg_Research_Data/text_noLem v1.csv\", 'rb') as file:\n",
    "#     binary_content = file.read()\n",
    "#     decoded_content = binary_content.decode('latin-1')\n",
    "#     csv_reader = csv.reader(decoded_content.splitlines())\n",
    "#     for row in csv_reader:\n",
    "#         dct[row[0]] = row[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_20_raw= pd.read_csv(r\"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\school performance data\\math-achievement-lea-sy2020-21.csv\")\n",
    "math_18_raw = pd.read_csv(r\"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\school performance data\\math-achievement-lea-sy2018-19.csv\")\n",
    "school_location = pd.read_csv(r\"C:\\Ziyuan Sui\\MSBA\\RA\\GARG\\school performance data\\school_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math_20_raw.shape,math_18_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_location.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_20 = math_20_raw[math_20_raw.CATEGORY=='ALL']\n",
    "math_18 = math_18_raw[math_18_raw.CATEGORY=='ALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the GRADE value consisitent\n",
    "math_20['GRADE'] = math_20['GRADE'].replace({'00': '0', '01': '1', '02': '2', '03': '3', '04': '4', '05': '5','06': '6', '07': '7', '08': '8'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math_20.shape,math_18.shape)\n",
    "print(math_20.LEAID.nunique(),math_18.LEAID.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_18.LEAID = math_18.LEAID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(math_20[math_20.PCTPROF=='.']),len(math_18[math_18.PCTPROF=='.']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform PCTPROF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process_value(value):\n",
    "    if isinstance(value,str):\n",
    "        if re.match(r'^\\d+$', value):  # Check for integer values\n",
    "            return value\n",
    "        elif re.match(r'^\\d+-\\d+$', value):  # Check for range like '40-44'\n",
    "            range_values = value.split('-')\n",
    "            return str((int(range_values[0]) + int(range_values[1])) // 2)\n",
    "        elif value.startswith('LT'):  # Check for 'LT'\n",
    "            return int(value[2:])\n",
    "        elif value.startswith('GT'):  # Check for 'GT'\n",
    "            return int(value[2:])\n",
    "        elif value.startswith('GE'):  # Check for 'GE'\n",
    "            return int(value[2:])\n",
    "        elif value.startswith('LE'):  # Check for 'LE\n",
    "            return int(value[2:])\n",
    "        elif value.startswith('PS'):  # Check for 'PS'\n",
    "            return 50\n",
    "        elif value.startswith('.'):  # Check for 'PS'\n",
    "            return 0\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the processing function to the 'PCTPROF' column\n",
    "math_18['PCTPROF'] = math_18['PCTPROF'].apply(process_value)\n",
    "math_20['PCTPROF'] = math_20['PCTPROF'].apply(process_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math_20.shape,math_18.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_table = math_18.merge(math_20,on=['LEAID','GRADE'],how='right',suffixes=('_18','_20'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_table.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_table[merge_table.PCTPROF_18.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_table[['PCTPROF_18','PCTPROF_20']].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_table[['PCTPROF_18','PCTPROF_20']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_table.difference = merge_table.PCTPROF_20 - merge_table.PCTPROF_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = merge_table[['']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# pos_to_keep = ['NOUN', 'PROPN', 'PRON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_dct = {k: [] for k in dct.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over each key, value in the original dictionary\n",
    "# for key, word_list in dct.items():\n",
    "#     # Form a sentence\n",
    "#     sentence = ' '.join(word_list)\n",
    "#     # Process the sentence\n",
    "#     doc = nlp(sentence)\n",
    "#     # Iterate over each token in the doc\n",
    "#     for token in doc:\n",
    "#         # If the token's pos is in the list of pos to keep, append it to the appropriate list in the new dictionary\n",
    "#         if token.pos_ in pos_to_keep:\n",
    "#             filtered_dct[key].append(token.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
